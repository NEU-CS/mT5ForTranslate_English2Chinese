{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d5f7fed2a840a1b84b2940d146d810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "path = os.path.join(\"..\",\"dataset\",\"tiny_stories\",\"en-zh\")\n",
    "data = load_dataset(\"json\",data_files={\"train\":os.path.join(path,\"train.jsonl\"),\"test\":os.path.join(path,\"valid.jsonl\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5Tokenizer\n",
    "from transformers import RobertaForSequenceClassification,RobertaTokenizer,get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.functional import F\n",
    "from torch.cuda.amp import autocast as autocast,GradScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import AdamW\n",
    "import bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration,Seq2SeqTrainingArguments,Seq2SeqTrainer\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"Translate English into  Chinese:\" + example['text'] for example in examples['src_text']]\n",
    "    tgts = [ example for example in examples['tgt_text'] ]\n",
    "    model_inputs = tokenizer(inputs,text_target=tgts,padding=True,truncation=True)  \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29559a8483a64e3f85597b63e9058fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenzied_data = data.map(preprocess_function,batched=True,remove_columns=['src_text','tgt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate English into Chinese:Once upon a time, there was a little girl named Lily. She loved to talk to her friends, and she loved to play with her toys. One day, she found a lemon in her kitchen. Lily thought the lemon was a toy, so she took it to her room to play with it. Lily started to feel helpless because the lemon was not fun like her other toys. She tried to talk to the lemon, but it did not talk back. Lily was sad and didn\\'t know what to do. Then, something unexpected happened. The lemon started to grow bigger and bigger! Suddenly, the lemon turned into a big, friendly lemon man. He could talk, and he was not helpless at all! He said, \"Hi Lily, I am Mr. Lemon. I was hiding in your kitchen, and now I am here to play with you.\" Lily was so happy and surprised. They played together all day long, and Lily had a new, fun friend.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenzied_data['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从前,有一个叫莉莉的小女孩。她喜欢和她的朋友聊天,她也喜欢玩她的玩具。一天,她在厨房里发现了一个柠檬。莉莉以为柠檬是玩具,所以她把它带到房间里玩。莉莉开始感到无助,因为柠檬不像她的其他玩具那样有趣。她试着和柠檬说话,但它不顶嘴。莉莉很难过,不知道该怎么办。然后,意想不到的事情发生了。柠檬开始变得越来越大!突然,柠檬变成了一个又大又友好的柠檬人。他会说话,一点也不无助!他说:“嗨,莉莉,我是柠檬先生。我躲在你的厨房里,现在我来和你一起玩。”莉莉既高兴又惊讶。他们整天都在一起玩,莉莉有了一个有趣的新朋友。</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenzied_data['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenzied_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenzied_data['train'],shuffle=True,collate_fn=collate_fn,batch_size = 4)\n",
    "eval_dataloader = DataLoader(tokenzied_data['test'] , collate_fn=collate_fn,batch_size = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "lr = 1e-5\n",
    "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  0%|          | 2/1000 [00:00<02:58,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前有一辆跑车,名叫斯皮迪。他喜欢开快车。一天,他在一座大山附近的路上行驶。他看到一块牌子上写着“危险的路”。但是斯皮迪不在乎。他想走得快。当斯皮迪上山时,他看到一只名叫伊万的慢乌龟。伊万说:“斯皮迪,这条路很危险。你不应该在这里走得快。”斯皮迪笑着说:“我不害怕。我是一辆跑车。”斯皮迪快速上山。但是这条路非常危险。有大石头和洞。斯皮迪差点掉进一个洞里。他很害怕。他停下来说:“伊万是对的。我在这条路上应该小心。”斯皮迪回到山下去找伊万。他说:“谢谢你警告我。你是个好朋友。”然而笑着说:“不客气,斯皮迪。我们应该在危险的道路上永远小心。”从那天起,斯皮迪和然而是最好的朋友。他们总是互相帮助保持安全。斯皮迪学会了在危险的道路上小心。', '从前,在一个小房子里,有一个善良的女孩,名叫莉莉。她有一面魔镜。每天,她都会选择一个新朋友在镜子里玩。一天,她选择了一只猫。猫很好,他们玩得很开心。第二天,莉莉选择了一只狗在镜子里玩。他们玩了一个球,玩得很开心。但是后来,意想不到的事情发生了。前一天的猫回到了镜子里。猫和狗开始打架。莉莉看到她的朋友打架很难过。她要求他们善待彼此。猫和狗停止了打架,看着莉莉。他们为让她难过而感到难过。然后,猫和狗成了朋友。他们都在镜子里一起玩耍,度过了快乐的一天。'] ['<pad> <extra_id_0>. Retrieved from \"https://en. <extra_id_1>.cn/\"</s>', '<pad> <extra_id_0>. They all had fun.</s><pad><pad><pad><pad><pad><pad><pad><pad>'] [0, 0]\n",
      "['从前,有一个叫露西的小女孩。她有一本特别的书,叫做日记。在这本日记里,她写了每天发生的事情。她也喜欢画画。日记是她最好的朋友。一天,露西发现了一块罕见的漂亮的石头。它闪亮光滑。她太高兴了!她把石头带回家,给她的父母看。他们也很开心。露西想保护石头的安全,所以她把它放在日记里。每天晚上,在她睡觉之前,露西都会打开日记,看看这块罕见的石头。她会写下她的一天,并画一张石头的照片。她的日记现在更加特别了。这是一个快乐事情发生的地方。露西和她的日记从此幸福地生活在一起。', '一天,一个叫蒂姆的小男孩在他的院子里发现了一个灯泡。他认为这是一个愚蠢的玩具。他把它给他的朋友萨姆看。“看看我发现的这个愚蠢的东西!”蒂姆说。萨姆看着灯泡说:“那不是玩具,是灯泡!”蒂姆和萨姆开始为灯泡争论起来。蒂姆想扔掉它,但萨姆想留着它。“我们问问我妈妈吧,”萨姆说。他们去找萨姆的妈妈,给她看了灯泡。她告诉他们这是一种特殊的灯泡,如果他们种植它,它可以长成一朵美丽的花。蒂姆和萨姆决定一起种植灯泡。他们在院子里挖了一个洞,把灯泡放进去。然后他们用泥土盖住它,给它浇水。每天,他们轮流给灯泡浇水,确保它有足够的阳光。一天,他们看到一片小小的绿叶从地里伸出来。他们太兴奋了!他们知道他们的灯泡正在长成一朵美丽的花。他们明白了有时候,看起来愚蠢的事情可能会变得非常特别。'] ['<pad> <extra_id_0>, a diary.</s>', '<pad> <extra_id_0>, but a bulb.</s>'] [0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<02:43,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一个叫米娅的年轻女孩和她的妈妈在树林里散步。他们走着走着,米娅听到灌木丛里有轻微的沙沙声。米娅的妈妈跪了下来,小声说:“让我们非常安静,米娅。”米娅很好奇,试图仔细看看,但她的妈妈把她拉了回来。从灌木丛里,一位女士走了出来。她穿着一件漂亮的绿色连衣裙,走得很慢。女士轻声说。“你准备好我将要揭示的事情了吗?”米娅的妈妈点了点头,但米娅很困惑。女士微笑着,慢慢地张开了手。里面是一块闪闪发光的蓝色石头。“这是给你的,米娅,”她说。米娅非常兴奋,立刻抓住了它。“这是森林的秘密,”女士解释道。“我把它给你,因为我认为你已经准备好了。”弥雅抬头看着母亲,不知道该怎么办。母亲安慰地笑了笑。弥雅拥抱着女士,感激森林的秘密。女士眼睛闪烁着光芒,说:“我们保守秘密,好吗?”弥雅点点头,已经梦想着带着她的秘密去冒险。', '从前,在一个小镇上,有一只叫基蒂的可怜猫。基蒂非常难过,因为其他动物会取笑她。他们会说:“你是一只可怜的猫!你没有像我们这样漂亮的家!”一天,基蒂走在一口井边。她看见一只叫鲍比的小鸟坐在井边。鲍比也很难过,因为其他鸟也会取笑他。“我这么小,他们嘲笑我,”鲍比说。基蒂和鲍比成了朋友。他们决定互相帮助,不让取笑让他们难过。他们在井边玩耍,一起玩得很开心。很快,其他动物看到他们有多开心,就不再取笑他们了。基蒂和鲍比很开心,他们一起住在井边。'] [\"<pad> <extra_id_0>, but her mother couldn't.</s>\", '<pad> <extra_id_0>, and they laughed.</s><pad><pad>'] [0, 0, 0, 0, 0, 0]\n",
      "['从前,有一个叫莎莉的小女孩。她喜欢在外面玩。一天,天开始下雨了。雨下得很大,弄出了很大的水坑。莎莉很难过,因为她不能在外面玩。莎莉的妈妈看到她看起来很难过。她说:“莎莉,我们今天为什么不接受雨水,在里面玩呢?”莎莉想了一会儿,然后笑了。她说:“好的,妈妈!我们在里面玩吧!”莎莉和她妈妈整天玩游戏,看书。他们玩得很开心!雨停了,太阳出来了。莎莉向外面看,看到了一道很大的彩虹。她很高兴自己接受了雨水,和妈妈一起度过了愉快的一天。', '一天,一个叫汤姆的小男孩去拜访他的朋友——鳄鱼。鳄鱼住在一个大湖里。汤姆和鳄鱼喜欢一起玩耍和聊天。一天,当汤姆去看鳄鱼时,他看到了一件非常悲伤的事情。鳄鱼一动不动。汤姆说:“醒醒,鳄鱼!我们玩吧!”但是鳄鱼没有醒来。汤姆以为鳄鱼已经死了。突然,鳄鱼睁开眼睛说:“惊喜吧!我没有死,汤姆!我只是在捉弄你!”汤姆很高兴他的朋友没有死。他们笑了,整天在一起玩耍。'] ['<pad> <extra_id_0>, and the sun came out.</s><pad>', '<pad> <extra_id_0>, a little boy named Tom</s>'] [0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:01<02:36,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,有一只名叫斑点的小狗。斑点喜欢玩他的玩具。一天,他发现了一个箱子。箱子又大又蓝。斑点对箱子里的东西非常好奇。斑点试图打开箱子,但他不能。他不知道如何打开它。斑点对箱子一无所知。他向他的朋友大红鸟寻求帮助。大红鸟知道如何打开箱子。他用他的喙打开它。在箱子里,他们发现了一只小猫。小猫又难过又害怕。斑点想救小猫。他和大红鸟把小猫从箱子里带了出来。他们和小猫一起玩,让她开心。小猫不再悲伤和害怕了。斑点、大红鸟和小猫成了最好的朋友。', '从前,有一只名叫波波的大猩猩。波波住在一个漂亮的动物园里,那里每天都有许多孩子来看他。波波有一个大水桶,用来玩水。一天,波波在家里发现了一块暗淡的灰色石头。他想把它做得闪亮漂亮。所以,他有了一个主意!他会把水倒在石头上清洗它。波波拿起他的大水桶,装满水。波波把水倒在暗淡的石头上。当水冲刷它时,石头开始发光。波波很高兴看到石头变得漂亮。他把闪亮的石头给所有来看他的孩子看。孩子们也很高兴,他们为波波鼓掌。'] ['<pad> <extra_id_0>, but they could not.</s>', '<pad> <extra_id_0>. - Maybe.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一个叫提姆的小男孩。他有一顶他非常喜欢的红色帽子。一天,提姆看到树叶上有一只娇嫩的蝴蝶。他想把它拿给朋友们看,于是他把蝴蝶放在帽子里。在路上,提姆看到一个大牌子,上面写着:“不要碰蝴蝶。”提姆既伤心又担心。他不想因为帽子里有蝴蝶而惹上麻烦。提姆苦苦思索着该怎么办。他知道留着蝴蝶是不对的。所以,他回到树叶上,放开了蝴蝶。提姆很高兴自己做了正确的事,尽管这很难。他跑向朋友,告诉他们蝴蝶的事,他们一起去看了。', '从前,有一块又大又贵的橡皮擦。它和许多其他橡皮擦一起住在一个盒子里。一天,一个叫艾米的小女孩发现了这个盒子。她非常高兴,因为她喜欢画画。艾米拿着昂贵的橡皮擦开始画画。她画了一只猫、一只狗和一棵树。但是,她犯了一个错误。她需要用橡皮擦来修复它。所以,她试图从橡皮擦上撕下一小块。但是橡皮擦太大太结实了。“拜托,你能帮我吗?”艾米问橡皮擦。橡皮擦想帮忙,所以它让艾米撕下一小块。艾米说:“谢谢你!”她用这一小块来修复她的画。现在,艾米和橡皮擦是朋友。他们每天一起画画和玩耍。从此以后,他们幸福地生活在一起。'] ['<pad> <extra_id_0>. - Mandarin Translations</s><pad><pad>', '<pad> <extra_id_0>, a few erasers.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:01<02:39,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,在一片大森林里,住着一只小鸟,名叫提米。提米是一只很小的鸟,它喜欢飞,喜欢和朋友们一起玩耍。但是有一天,提米感到不舒服。它的肚子疼,不想玩了。提米的妈妈看到他不舒服,她想:“也许它饿了。”于是,她去找一些食物喂提米。她看了又看,终于找到了一些美味的虫子。她把它们带回提米身边,喂他吃。吃完虫子后,提米感觉好多了。他知道了饿了吃东西很重要。但是后来,意想不到的事情发生了。提米的肚子开始越来越大!原来,这些虫子是神奇的虫子,让他长得非常快。提米变成了一只大鸟,比以往任何时候都飞得更高更快。这个故事的寓意是永远听你妈妈的话,因为她知道什么对你最好。', '一天,一只名叫斑点的湿狗正在寻找它的主人。他在一棵大树周围偷看,看到了一个叫苏的小女孩。斑点跑向苏说:“嗨!我在找我的主人。你能帮我吗?”苏看着湿狗说:“是的,我可以帮你找到你的主人。”他们走啊走,却找不到斑点的主人。斑点开始感到难过。然后,他们看到了一个叫蒂姆的男孩。蒂姆说:“嘿,那是我的狗!”斑点很高兴看到他的主人。苏和蒂姆帮助斑点变干,他们都在一起玩耍。这一天得救了,他们都很开心。'] ['<pad> <extra_id_0>, because it is a worm.</s>', '<pad> <extra_id_0>. - Mandarin Translations</s><pad><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['一天,一只猫和一只狗在一个宁静的公园里。他们喜欢玩耍,玩得很开心。猫对狗说:“我们来比赛吧。我们将看看谁跑得最快。”狗同意了,他们做好了准备。当他们开始奔跑时,一只大鸟从天而降。小鸟说:“停!我想给你讲一个关于历史的故事。这是关于一只猫和一只狗,他们是最好的朋友。”猫和狗停止了奔跑,听了小鸟的故事。小鸟告诉他们,故事中的猫和狗总是互相帮助。他们是非常好的朋友。公园里的猫和狗互相看了看,笑了。他们决定不再比赛了。相反,他们一起玩,成为最好的朋友,就像鸟告诉他们的历史故事一样。', '安娜和本是双胞胎。他们喜欢和爸爸妈妈一起去博物馆。博物馆有很多东西可以看和学习。安娜喜欢动物,本喜欢汽车。一天,他们去博物馆,看到一个大标志。标志上写着“拉链线”。爸爸妈妈说他们可以试试。安娜和本很兴奋。他们戴上头盔和手套。他们爬上梯子。他们看到一根带把手的长绳子。他们握住把手,在空中拉上拉链。他们感觉到风,看到树。他们欢笑和尖叫。他们来回拉拉链。他们玩得很开心。完成后,他们对帮助他们的人说谢谢。他们去博物馆看更多的东西。他们看到一只大恐龙和一枚闪亮的火箭。他们学习新单词和事实。他们有美好的一天。他们告诉爸爸妈妈他们想回来。爸爸妈妈说他们为他们感到骄傲。他们拥抱亲吻。他们开心地回家了。'] ['<pad> <extra_id_0>. They were very good friends.</s>', '<pad> <extra_id_0>. They have a good day.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:01<02:35,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,一个小房间里有一张大床。一个叫莉莉的小女孩住在房子里。莉莉很难铺床。一天,她的妈妈说:“莉莉,你需要铺上床单,把你的床弄得又好又整齐。”当莉莉试图铺上床单时,意想不到的事情发生了。一只小老鼠从床上跳了出来!莉莉非常惊讶。她说:“哦,不,小老鼠!你不能呆在我的床上。”小老鼠看着莉莉说:“对不起,我只是想找一个温暖的地方睡觉。”莉莉为老鼠感到难过,所以她帮他在外面找了一个新家。之后,莉莉铺上床单,自己铺床。她非常自豪,她妈妈也很高兴。', '从前,在一个小镇上,有一个叫艾米的小女孩。艾米喜欢和她的朋友们在公园里玩。一个阳光明媚的日子,在玩的时候,艾米看到了一个牌子。牌子上有一张笑脸的照片,上面写着:“要有礼貌。”艾米想礼貌一点,就对她的朋友说“请”和“谢谢”。但是后来,艾米看到她的朋友提米捏了另一个朋友莉莉。莉莉很难过,哭了起来。艾米知道捏是不礼貌的。艾米走到提米面前说:“提米,还记得我们看到的牌子吗?上面写着要有礼貌。捏是不礼貌的。让我们向莉莉说对不起,善待彼此。”提米想了想,知道艾米是对的。他对莉莉说对不起,他们都开心地在一起玩。从那天起,艾米、提米和莉莉总是试着对彼此礼貌友好。他们知道礼貌让每个人都开心,让一起玩更有趣。从此他们都过着幸福的生活。'] ['<pad> <extra_id_0>, a tiny mouse jumped</s>', '<pad> <extra_id_0>. Please reply.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一只野猫。这只猫很老了。这只猫住在一所古老的房子里。这只猫喜欢玩耍和奔跑。这只猫有很多朋友。一天,猫去了树林。猫看到了一棵大树。猫感到很开心。猫想爬树。猫爬上去,爬上去,爬上去。但是,猫看到了新的东西。猫看到了一只大鸟。这只鸟不是朋友。这只鸟是妈妈。这只鸟有了一个孩子。猫感觉很好。猫没有和小鸟玩。猫下去回家了。猫感觉很好。', '从前,有一只友好的鸟。一天,这只鸟想找个好地方坐下。然后,这只鸟看到了一个完美的地方——一个又大又软的巢!这只鸟跳了进去,让自己很舒服。这是这只鸟找到的最舒适、最友好的巢。这只鸟闭上眼睛,打了个盹。过了一会儿,这只鸟醒来时感觉又好又暖和。巢是如此舒适,这只鸟决定永远呆在那里。花园里所有的其他鸟都认为这只鸟找到了一个如此友好的巢真是太好了。每天,友好的鸟都会回到它的巢休息。这只鸟在那里非常开心,它再也不想离开了!友好的鸟和它的巢成了最好的朋友,从此他们幸福地生活在一起。'] ['<pad> <extra_id_0>. - Maybe you remember me</s>', '<pad> <extra_id_0>, the bird would leave.</s><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:01<02:38,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一只小鳄鱼去散步。他非常粗心,不看自己要去哪里。他喜欢四处偷看,但他没有注意眼前的东西。鳄鱼遇到了一只大青蛙。青蛙说:“小心点,小鳄鱼!你必须看看你要去哪里。如果你不这样做,可能会发生不好的事情。”小鳄鱼不听大青蛙的话。他只是不停地走,四处偷看。很快,粗心的鳄鱼掉进了一个深洞。他出不去了。他大声呼救,但没有人来。小鳄鱼非常难过。这个故事的道德价值是:永远听取好的建议,小心你走的地方。', '从前,有一只聪明的猫,名叫胡须。胡须喜欢玩他的球。一天,他看到一个看起来像监狱的大盒子。他非常好奇。胡须走到监狱前,小声说:“喂?有人在吗?”一只名叫Squeaky的小老鼠听到了他的声音,小声回答说:“嗨!我被困在这个监狱里了。你能帮帮我吗?”胡须想帮助他的新朋友。他想了又想。然后,他有了一个主意!他用他的球打破了监狱。球弹了起来,击中了监狱,门开了。Squeaky跑出监狱,拥抱了胡须。“谢谢你救了我!”他说。从那天起,胡须和Squeaky是最好的朋友。他们每天都和球一起玩,他们再也不害怕监狱了。'] ['<pad> <extra_id_0>. - Maybe you could.</s><pad>', '<pad> <extra_id_0>. - a very funny story</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,在一片大森林里,住着一只小老虎。老虎喜欢和他的朋友们一起玩。他们会跑、跳,整天玩得很开心。一天,老虎发现一扇大门上有一把锁。这扇门看起来很旧,很粗糙。老虎很好奇,想看看门后有什么。他让他的朋友们帮他打开锁。他们都试过了,但打不开。森林里的动物告诉老虎,门被锁是有原因的。他们说这是为了保护每个人的安全。老虎不听,一直试图打开锁。一天,一只聪明的老猫头鹰来到老虎面前,告诉他有时候东西被锁上了,以保护我们免受危险。老虎终于明白了,不再试图开门。从那天起,老虎和他的朋友们在森林里安全地玩耍,知道锁着的门在那里是为了保护他们的安全。这个故事的寓意是,有时事情是为了我们好而锁上的,我们应该信任和倾听那些更了解的人。', '从前,有一只毛茸茸的猫。猫喜欢在外面玩。一天,猫发现了一个大盒子。盒子是关着的。猫想打开盒子。猫试着用爪子打开盒子。过了一会儿,盒子打开了。盒子里,有灰烬。猫不知道灰烬是什么。猫玩灰烬。猫被灰烬弄脏了。猫的皮毛不再干净了。猫回家了。它的家人看到了脏猫。他们笑着帮猫打扫卫生。猫又开心又毛茸茸的。'] ['<pad> <extra_id_0>. - a chinese dictionary</s>', '<pad> <extra_id_0>. They laughed.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [00:02<02:37,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一个叫米娅的小女孩遇到了麻烦。她找不到她的校服。她需要它去上学。米娅在她的房间里到处找,但她找不到。米娅问她妈妈:“妈妈,我的校服在哪里?我上学需要它。”她妈妈说:“我们一起去找吧。”他们在壁橱里、床底下,甚至洗衣房里都找遍了。但是他们找不到校服。然后,米娅的小弟弟走进了房间。他说:“我去拿你的校服!我把它放在我的房间里了。”米娅和她妈妈去了他的房间,找到了校服。米娅很高兴。她穿上它,脸上带着灿烂的笑容去了学校。', '从前,有一个害羞的小女孩,名叫莉莉。莉莉有一朵漂亮的花,叫做罂粟。她非常喜欢她的罂粟。一天,她带着她的罂粟去了公园。在公园里,莉莉看见了一个叫汤姆的男孩。汤姆正在玩球。汤姆看见莉莉的罂粟,说:“那是什么?”莉莉感到害羞,但她想解释一下她的罂粟。她说:“这是罂粟。它是一朵漂亮的花。”汤姆看着罂粟笑了。他说:“我喜欢你的罂粟。我可以和你一起玩吗?”莉莉感到高兴,说:“是的,你可以和我和我的罂粟一起玩。”于是,莉莉和汤姆一起带着罂粟在公园里玩。他们在一起玩得很开心。害羞的小女孩莉莉交了一个新朋友,汤姆。他们都喜欢漂亮的罂粟。从那天起,莉莉和汤姆一起和罂粟在公园玩耍。他们非常开心。'] ['<pad> <extra_id_0>. 中文文言</s><pad><pad><pad><pad>', '<pad> <extra_id_0>. They loved playing together.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一个叫鲍勃的秃头男人。鲍勃有一个很大的梦想。他想触摸月亮。每天晚上,他都会看着月亮,希望自己能触摸到它。一天,鲍勃发现了一个非常高的梯子。他想:“也许我可以用这个梯子触摸月亮!”于是,他把梯子靠在自己的房子上,爬了上去,爬了上去,爬了上去。但是梯子不够高,够不到月亮。鲍勃很难过。就在这时,一只大鸟飞过。小鸟看到鲍勃,问:“你为什么难过?”鲍勃告诉小鸟他触摸月亮的梦想。小鸟说:“我可以帮你!”小鸟抱起鲍勃,把他高高地飞向天空。鲍勃伸出手,有那么一会儿,他觉得自己能触摸到月亮。他太高兴了。从那天起,鲍勃和大鸟成了最好的朋友。', '从前,有一个叫汤姆的猎人。他喜欢穿着绿色的衣服和大靴子。每天,他都去树林里找动物。一个雨天,树林里非常潮湿。汤姆走啊走,但他没有看到任何动物。他感到很难过。然后,他看见一只小兔子藏在灌木丛下。汤姆说:“你好,小兔子!你为什么藏起来?”兔子回答说:“我藏起来是因为我不想在雨中淋湿。”汤姆微笑着说:“别担心,我会帮你的。”汤姆脱下他的大帽子,把它戴在兔子身上,这样它就不会淋湿了。他们成了朋友,一起在树林里玩耍。从那天起,猎人和兔子是最好的朋友,他们总是互相帮助。'] ['<pad> <extra_id_0>, a big bird flew by.</s>', \"<pad> <extra_id_0>, but they weren't.</s>\"] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:02<02:35,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,有一个叫苏的女孩。苏喜欢卖柔软的东西。一天,苏发现了一根树枝。树枝不柔软,但苏也想卖掉它。苏带着树枝去了公园。她试图把树枝卖给她的朋友。但是她的朋友们不想买树枝。他们只想买柔软的东西。苏很难过。然后,一场大风来了。风把树枝吹走了。树枝飞了起来。但是,风让树枝变了。树枝变软了!苏的朋友们看到了柔软的树枝,现在就想买。苏很高兴,把柔软的树枝卖给了她的朋友。', '一天,一个叫苏的小女孩饿了。她去厨房盯着大冰箱。她想找些好吃的东西吃。当她打开冰箱门时,苏非常小心。在冰箱里,她看到了一个红色的大苹果。苏的妈妈说:“小心苹果,它很特别。”苏不知道为什么苹果很特别,但她听了妈妈的话。第二天,苏发现了为什么苹果很特别。当她吃的时候,她感到非常开心,精力充沛。苏玩了一整天,再也不觉得饿了。她很高兴自己听了妈妈的话,对这个特别的苹果很小心。'] ['<pad> <extra_id_0>, but she wanted to sell it too.</s>', '<pad> <extra_id_0>, but it is not a special apple.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一个叫卡特里娜的小女孩。她非常开朗,总是喜欢在户外玩耍。一天,卡特里娜正在花园里玩耍,这时她注意到草地上有一个托盘。托盘已经滚开了,有掉进池塘的危险。卡特里娜跑过去救托盘。她安全地抓住它,把它带回草地上。她很高兴自己救了它。卡特里娜把托盘放下,友好地拍了拍它。退一步,开朗的小女孩钦佩她的工作。卡特里娜知道她做了一些特别的事情——而且都是靠自己。她很自豪,她救了托盘!', '从前,有一个小男孩。他喜欢到外面去探险。一天,他听到街上传来响声。他停下来听。听起来像是一个人在卖什么东西。他想知道那是什么。小男孩跑去看发生了什么事。当他到达那里时,他看见一个人站在拐角处。他正在卖一些玩具。小男孩跑向他,问:“你在卖什么?”那个人回答说:“我在卖玩具!它们很便宜,也很有趣。你想买一个吗?”小男孩想了一会儿说:“是的,我会的!”他很快挑选了一个玩具,递给那个人一些钱。那个人微笑着说:“谢谢你!玩得开心!”小男孩谢过那个人,跑回家。他迫不及待地想把他的新玩具给朋友们看。结束。'] ['<pad> <extra_id_0> a tray in the grass</s><pad>', '<pad> <extra_id_0>. Please leave a comment</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [00:02<02:35,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一只名叫基蒂的顽皮猫去散步。她看见地上有一个石灰。基蒂以为那是一个球,就和它玩耍。她用爪子推着它,玩得很开心。基蒂遇到了一只名叫马克斯的狗。马克斯也看到了石灰。他说:“基蒂,我能和石灰一起玩吗?”基蒂说:“是的,马克斯,我们一起玩。”他们和石灰一起玩,玩得很开心。但是后来,石灰滚到了街上。基蒂和马克斯追着它跑。他们没有看到大车来了。汽车撞上了石灰,它“啪”的一声!基蒂和马克斯尖叫起来。他们很难过,因为他们的石灰不见了。他们学会了在街道附近玩耍时要小心。', '从前,在一个繁忙的小镇上,住着一个叫莉莉的女孩。莉莉喜欢冰。她喜欢吃冰,玩冰,甚至用冰做艺术品。一天,莉莉有了一个大主意。她想做有史以来最大的冰塔!莉莉问她的朋友汤姆:“你想帮我做一个最大的冰塔吗?”汤姆说:“是的!我们开始吧!”他们非常努力地工作,把冰放在冰的上面。他们非常忙,但一开始没有成功。冰塔一直往下掉。莉莉和汤姆没有放弃。他们一次又一次地尝试。最后,他们成功了!冰塔很高,很漂亮。镇上的每个人都来看它。莉莉和汤姆非常高兴。他们学到了如果他们继续努力,他们可以成功,即使是困难的时候。'] ['<pad> <extra_id_0>, a lime rolled into the street</s>', \"<pad> <extra_id_0>, but they can't.</s><pad>\"] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一只鸟。这只鸟有漂亮的羽毛。这只鸟为自己的羽毛感到骄傲。它喜欢把它们展示给所有的朋友。它的朋友也喜欢看漂亮的羽毛。一天,下雨了。这只鸟出去玩了。它喜欢在雨中玩耍。这只鸟全身湿透了。它的羽毛泡了一大泡。这只鸟很开心。它喜欢感受雨水打在羽毛上。雨停了,鸟回家了。它向朋友们展示了湿羽毛。朋友们也喜欢湿羽毛。这只鸟仍然很自豪。它喜欢在雨中玩耍,泡一大泡。这只鸟和它的朋友每天都在一起玩。他们都很开心。', '从前,有一个叫苏的小女孩。苏有一个秃顶的姑姑,名叫简。简姑姑喜欢做东西。一天,简姑姑和苏正在玩积木。简姑姑说:“苏,让我们把积木连接起来,做一个大塔!”苏很高兴,帮助她的姑姑。他们把积木放在一起,一个在另一个上面。塔长得很高。突然,一只小鸟从窗户飞了进来。小鸟落在塔顶上。塔摇晃着,掉了下来。苏和简姑姑很惊讶。他们笑着说:“让我们再试一次!”'] ['<pad> <extra_id_0>. They were all very happy.</s>', '<pad> <extra_id_0> a tower. -</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [00:03<02:31,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一个叫真的小女孩去公园。她在一棵大树下看到了一个神秘的盒子。真对这个盒子非常好奇。她试图打开它,但它被锁上了。她环顾四周,想找到一把钥匙。真看见一个小男孩在玩钥匙。她问他:“我可以试试你的钥匙打开盒子吗?”小男孩说:“可以,你可以试试。”真拿着钥匙,试图打开那个神秘的盒子。钥匙不起作用,但真没有放弃。真一直在寻找合适的钥匙。她在秋千附近找到了另一把钥匙。她试了试新钥匙,盒子打开了!盒子里,有许多五颜六色的玩具。真和小男孩非常开心。他们整天都在玩玩具,玩得很开心。', '一天,一只名叫鲍勃的肥猫去散步。他看见一棵大树,就想爬上去。于是,他跳了起来,开始爬。当他爬上去时,他看见一只湿漉漉的小鸟坐在树枝上。小鸟看起来很难过。鲍勃问:“你为什么难过,湿漉漉的小鸟?”小鸟说:“我不能飞,因为我的翅膀湿了。我掉进了水坑里,现在我被困住了。”鲍勃想帮助小鸟。他有了一个主意!他用爪子从树上抓起一片大叶子。他把叶子给了小鸟,说:“用这个擦干你的翅膀。”小鸟微笑着,用叶子擦干。但是,意想不到的事情发生了。随着小鸟擦干翅膀,它开始变得越来越大!这只鸟根本不是鸟,而是一种神奇的生物!这只生物感谢鲍勃的帮助,飞走了,留下了一条闪闪发光的痕迹。鲍勃很高兴他能帮忙,继续攀登,兴奋地想看看这棵树还有什么惊喜。'] ['<pad> <extra_id_0>, but they did not.</s>', '<pad> <extra_id_0>, a fairy tale.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['一天,一个叫艾米的小女孩去她朋友家玩。他们玩玩具和跑来跑去玩得很开心。然后,艾米的朋友莉莉向她妈妈要了些茶。莉莉的妈妈为女孩们泡茶,他们坐下来喝。当他们喝茶时,莉莉说:“这茶太刺鼻了。我不喜欢它。”艾米尝了尝她的茶,同意了。她说:“是的,不好。但是我们还是应该对你妈妈说谢谢。”所以,他们都对莉莉的妈妈说谢谢,尽管他们不喜欢这茶。后来,莉莉的妈妈回来问他们是否喜欢这茶。莉莉和艾米告诉她这茶很刺鼻。莉莉的妈妈笑着说:“哦,我知道发生了什么。我给错你茶了。让我给你泡一杯新的。“她给他们泡了新茶,味道好多了。女孩们明白了礼貌和说谢谢是很重要的,即使事情没有按计划进行。', '汤姆和安娜正在公园里玩耍。他们喜欢假装自己是骑士和公主。汤姆有一根棍子,他用它作为武器。安娜有一顶她用花做的王冠。“看,安娜,我有一件武器。我可以和坏人战斗,保护你,”汤姆说。他在空中挥舞着棍子。“那很好,汤姆,但是我饿了。你能给我带些好吃的吗?”安娜问。她坐在长凳上,把王冠戴在头上。“好的,安娜,我给你带些好吃的。在这里等着,我很快就回来,”汤姆说。他跑到小吃摊,买了一块饼干和一杯果汁。他回到安娜身边,把饼干和果汁给她。“给你,安娜,我给你带了些好吃的。这是饼干,这是果汁。它们非常好。你可以和我分享,”他说。“谢谢你,汤姆,你真好。这是美味的饼干和美味的果汁。你是个好骑士,我是个快乐的公主。我们可以分享并成为朋友,”安娜说。她微笑着咬了一口饼干。他们吃饼干,喝果汁。他们快乐而充实。他们继续在公园里玩耍。他们玩得很开心,他们彼此相爱。'] ['<pad> <extra_id_0>, a little girl named Amy.</s>', '<pad> <extra_id_0>. They are very happy.</s><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [00:03<02:37,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,一个叫安娜的小女孩有一双红色的靴子。她非常喜欢她的靴子。一天,天开始下雪了。安娜想穿着靴子在外面玩。她穿上靴子,出去在雪地里玩。安娜玩的时候,她发现了一个大冰块。她想摸摸它,但是当她摸摸它的时候,她的手感觉要冻僵了。安娜很害怕,跑回了自己的房子。她告诉妈妈发生了什么。她妈妈给了她一个甜蜜的拥抱,并告诉她不要担心。第二天,安娜和她妈妈带着温暖的毯子回到了冰块。他们把毯子放在冰块上,它开始融化了。安娜很高兴她的手不再冻僵了。她整天穿着红色的靴子在雪地里玩耍。', '从前,有一只小狗叫托托。他和他最好的朋友——一只叫咪咪的猫——住在一间小房子里。他们每天都在一起玩耍,非常开心。一天,托托和咪咪发现了一个红色的大球。他们都想和它玩,但是只有一个球。托托说:“我想玩球!”咪咪说:“不,我想玩球!”他们开始吵架,互相非常生气。他们都感觉很糟糕。看着他们的妈妈说:“托托和咪咪,你们不应该吵架。你们是朋友。你们为什么不轮流玩球呢?”托托和咪咪面面相觑,说:“好吧,妈妈。”他们轮流玩球,很快又开心了,像朋友一样一起玩。'] ['<pad> <extra_id_0>. - Maybe. Maybe.</s>', '<pad> <extra_id_0>, a very happy day.</s><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,一个叫蒂姆的小男孩住在一所小房子里。一天,蒂姆早早醒来,看到厨房里有一个微小的火焰。他很害怕,不知道该怎么办。他跑向妈妈,说:“妈妈,厨房里有一个火焰!”他妈妈走到厨房,看到火焰只是一支小蜡烛。她笑着说:“蒂姆,这不是一个大火焰,只是一支蜡烛。但是我很高兴你告诉我这件事。”蒂姆感觉好多了,看着妈妈吹灭蜡烛。第二天,蒂姆和妈妈去了公园。他们看到一块大石头,蒂姆试图举起它,但是太难了。他妈妈说:“没关系,蒂姆。有时事情很艰难,但我们总是可以寻求帮助。”就在这时,一个强壮的人走过来,帮助蒂姆举起岩石。在岩石下,他们发现了一块漂亮闪亮的石头。蒂姆了解到,当事情困难时寻求帮助是件好事,有时当我们一起工作时,会发现意想不到的惊喜。', '一天,一个叫莉莉的小女孩和她妈妈一起去公园。他们看见一棵大树,荡秋千很舒服。莉莉问她妈妈:“我可以玩秋千吗?”她妈妈说:“可以,你可以玩,但是数一数你来回荡秋千的次数。”莉莉开始荡秋千,数一数。一、二、三、四、五......当她荡秋千时,她看见一只小鸟飞过。小鸟落在树上,问莉莉:“我可以和你一起荡秋千吗?”莉莉很惊讶,因为小鸟会说话!她说:“可以,你可以和我一起荡秋千!”小鸟和莉莉成了朋友。他们一起在公园里荡秋千,一起玩。小鸟也能数一数他们来回荡秋千的次数。对莉莉和她的新朋友会说话的鸟来说,这是公园里有趣的一天。'] ['<pad> <extra_id_0>, but sometimes things are really hard.</s>', '<pad> <extra_id_0>, a bird could talk.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [00:03<02:30,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一个叫苏的女孩想烤一个蛋糕。她戴上妈妈的长面纱,假装成一个成年厨师。她让她的朋友汤姆帮她。苏说:“汤姆,我们烤一个大蛋糕吧!”汤姆很兴奋,说:“是的,我们开始吧!”他们混合蛋糕的东西,把它放在烤箱里。他们等着蛋糕烤好。在他们等待的时候,他们玩着长面纱,轮流戴着它。蛋糕做好后,苏和汤姆把它从烤箱里拿出来。他们把长面纱放在桌子上,把蛋糕放在上面。他们为他们的大蛋糕感到骄傲。他们的朋友过来了,他们都一起吃了蛋糕。对苏、汤姆和他们的朋友来说,这是有趣的一天。', '从前,有一块又大又干的田野。在田野里,有一个红色的小帐篷。一个叫马克的男孩住在帐篷里。马克是一个快乐的男孩,他喜欢整天在田野里玩耍。一个阳光明媚的日子,马克和他的朋友萨姆去外面玩。他们在干燥的田野里又跑又跳。他们笑了,玩得很开心。马克和萨姆喜欢在帐篷附近玩,所以如果他们累了或饿了,他们可以进去。过了一会儿,马克和萨姆渴了。他们走进帐篷喝了些水。然后,他们又回到外面玩了一会儿。他们一直玩到太阳下山,天空变黑。马克和萨姆道别,马克回到帐篷里睡觉。'] ['<pad> <extra_id_0> a sponge cake.</s><pad>', '<pad> <extra_id_0>. They called Mark and Sam</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['一天,一个叫蒂姆的小男孩和他的妈妈去了一家现代食品店。食品店有许多美味的东西可以吃。蒂姆看到墙上有一份菜单。菜单上有食物和饮料的图片。蒂姆看着菜单选择他想吃的东西。蒂姆的妈妈俯下身来,问他从菜单上想要什么。蒂姆指着一个红色的大苹果和一杯牛奶。他的妈妈微笑着说:“不错的选择,蒂姆!”她为他点了苹果和牛奶。他们坐在一张桌子旁,等待他们的食物。当食物来的时候,蒂姆吃了他的苹果,喝了他的牛奶。他非常高兴。他们吃完后,蒂姆的妈妈俯下身来拥抱了他。他们吃饱了肚子,笑容满面地离开了现代食品店。', '莉莉和汤姆很高兴搬到新房子。他们有许多盒子要拆。他们想看看他们的新房间和玩具。他们帮爸爸妈妈把盒子搬到楼上。莉莉看到地板上有一枚闪亮的硬币。她捡起来给汤姆看。“看,汤姆,一枚硬币!也许我们可以用它买糖果!”她说。汤姆也想要这枚硬币。他试图从莉莉那里抢过来。莉莉不想分享。她紧紧地握着硬币。“我的,我的,我的!”她喊道。他们开始打架。他们互相拉扯、推搡和抓伤。他们没有看到他们的爸爸妈妈来了。爸爸妈妈很生气。他们看到莉莉和汤姆为一枚硬币打架。他们看到盒子掉下来摔碎了。他们看到他们的新衣服、书和玩具变得又脏又破。他们从莉莉和汤姆那里拿走了硬币。他们责备他们贪婪和淘气。他们让他们收拾残局。他们不让他们玩他们的新东西。莉莉和汤姆很难过。他们希望他们没有为硬币而争吵。他们希望他们是善良和乐于助人的。他们希望他们有美好的一天。但是太晚了。他们度过了糟糕的一天。'] ['<pad> <extra_id_0>. They were very happy.</s>', '<pad> <extra_id_0> a candy can.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [00:04<02:36,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一天,一个叫蒂姆的男孩和他妈妈去了公园。他们开着他们巨大的汽车去兜风。蒂姆很兴奋能和他的朋友们一起玩。在公园里,蒂姆和他的朋友们玩了很长时间。他们玩秋千和滑梯。蒂姆玩得太开心了,以至于他忘记了一些非常重要的事情。他忘记了他妈妈在哪里!蒂姆开始寻找他的妈妈。他看了看秋千和滑梯,但她不在那里。然后,他看到了意想不到的事情。在巨大的汽车附近有一个又大又有趣的小丑!小丑正在为孩子们做气球。蒂姆走到小丑面前,问他是否见过他妈妈。小丑微笑着说:“是的,我见过她。她去给你买冰淇淋了。”蒂姆太高兴了!小丑给了蒂姆一个气球,他们一起等他妈妈。很快,蒂姆的妈妈带着冰淇淋回来了,他们一起享受了一顿甜蜜的款待。', '一天,一个叫蒂姆的男孩准备和他的家人一起去一次大旅行。他们需要为他们的汽车加油。蒂姆的爸爸说:“我们必须加油才能让汽车发动起来。”在加油站,蒂姆看到了一个大气球。他非常想要它。他的妈妈说:“如果你能够到它,你就可以拥有它。”蒂姆试了又试,但他拿不到气球。他很难过。然后,一个好心人来帮助蒂姆。他说:“我会帮助你成功的。”那个人把蒂姆举起来,蒂姆拿到了气球。他非常高兴。蒂姆说:“谢谢你!”那个人微笑着说:“不客气!”现在,蒂姆和他的家人准备开始他们的大旅行。'] ['<pad> <extra_id_0>. They went to the park.</s>', '<pad> <extra_id_0>, a balloon.</s><pad><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['从前,有一只五颜六色的鸟。这只鸟喜欢坐在麦田附近的一块大石头上。每天,这只鸟都会唱一首快乐的歌。一天,一个叫莉莉的小女孩来到麦田。她听到了这只鸟的歌声,说:“你好,小鸟!我喜欢你的歌声。你能再给我唱一遍吗?”小鸟点点头,又唱了一遍这首歌。莉莉拍手笑了起来。但是后来,意想不到的事情发生了。一阵大风来了,把小麦吹得到处都是。小鸟不得不紧紧抓住岩石。风停了,小麦已经在地上画了一幅大画。它看起来像一颗巨大的心。莉莉和小鸟既惊讶又高兴。他们知道这是风给他们的特殊礼物。', '一天,一只大猫和一只小狗在一个整洁的房间里玩耍。他们喜欢四处走动,一起玩得很开心。猫说:“我有跳得高的力量!”狗说:“我跑得很快!”他们玩的时候,听到一声巨响。他们环顾四周,看到了一个大盒子。猫和狗非常惊讶。他们不知道盒子是从哪里来的。猫说:“让我们打开盒子,看看里面有什么!”当他们打开盒子时,他们发现了一个大玩具机器人。机器人有移动房间里东西的力量。猫和狗和机器人一起玩得很开心。他们和机器人一起在房间里走来走去,使它更加整洁。他们都成了好朋友。'] ['<pad> <extra_id_0>. Please select a language.</s><pad><pad>', '<pad> <extra_id_0>. They moved things around the room.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [00:04<02:32,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,在一所小房子里,有一只小狗,名叫蒂尼。蒂尼喜欢玩耍和弄脏。一天,蒂尼出去发现了一个大泥坑。他跳进去玩了一整天。他非常开心,玩得很开心。当蒂尼回家时,他妈妈看到了他,说:“蒂尼,你真脏!你需要马上洗澡!”蒂尼不喜欢洗澡,但他知道他妈妈是对的。所以,他去了浴室,准备洗澡。蒂尼试图找到一种让洗澡变得有趣的方法,但他就是不喜欢。他溅了溅水,玩了玩他的玩具,但他仍然感到悲伤。洗澡结束时,蒂尼很干净,但他想念泥坑。他希望他能回去再玩一次。', '从前,有一个王子。他是一个多毛的王子。他住在一所大房子里。王子有很多朋友。他们喜欢和他一起玩。一天,王子遇到了一个女孩。她人很好。她想给他看点东西。王子很高兴。他想看看她要展示什么。女孩带王子去了公园。公园很漂亮。有许多花。王子和女孩在公园里玩耍。他们玩得很开心。王子喜欢这个公园。他非常高兴。结束。'] ['<pad> <extra_id_0>, but he did not like it.</s>', '<pad> <extra_id_0>. Please select language.</s><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['一天,一个叫米娅的小女孩去外面玩。太阳很热,晒在她的皮肤上感觉很刺耳。她看到一个大盒子,里面有许多玩具。米娅觉得按颜色分类玩具会很有趣。当她分类玩具时,一个叫汤姆的男孩来玩了。他说:“嗨,米娅!我能帮你分类玩具吗?”米娅微笑着说:“是的,欢迎汤姆!你可以帮我。”他们一起把玩具分类成成堆的红色、蓝色、绿色和黄色。他们一起玩得很开心。当他们完成后,他们跑进去喝杯冷饮,躲避严酷的阳光。', '从前,有一个笨拙的士兵,名叫汤姆。他不像其他士兵那样擅长行军。他会经常绊倒。他的朋友们会戏弄他说:“汤姆,你需要像我们一样学习走路!”一天,汤姆在森林里散步,这时他遇到了一只小鸟。小鸟很难过,因为它不会飞。汤姆为小鸟感到难过,说:“别担心,小鸟。我会帮你学会飞的。”汤姆和小鸟每天练习。他们成了很好的朋友。其他士兵看到汤姆如何帮助小鸟,不再戏弄他了。他们学会了善良胜过戏弄。最后,小鸟学会了飞,汤姆成了一名更好的士兵。他们俩都很幸福,从此以后森林里的每个人都过着幸福的生活。'] ['<pad> <extra_id_0>, a very tiny girl.</s>', '<pad> <extra_id_0> a better soldier.</s><pad><pad><pad>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [00:04<02:36,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从前,有一个很大的广告牌。它非常重要。广告牌上有一张猫的照片。每天,人们路过都会看到这只猫。他们会微笑着谈论这只猫。一天,一个叫蒂姆的小男孩看到了广告牌。他看着这只猫,认出了它。“那是我的猫,路威!”蒂姆说。他很高兴看到他的猫出现在重要的广告牌上。蒂姆回到家,告诉了他妈妈广告牌的事。他妈妈为路威感到非常自豪。他们一起去看了广告牌。他们和路威以及广告牌合了影。从此他们都过着幸福的生活。', '从前,在一个著名的大宫殿里,住着一位善良的国王和王后。他们有一个小女孩,名叫莉莉。她喜欢玩她的玩具,在宫殿里跑来跑去。一天,莉莉发现宫殿里有一扇小门。她想看看里面有什么。她试图打开它,但它被锁上了。莉莉向她的妈妈——王后——要钥匙开门。王后给了莉莉钥匙,她打开了门。在里面,她发现了一个美丽的花园,里面有鲜花和蝴蝶。莉莉在花园里玩了一整天,玩得很开心。从那天起,著名的宫殿有了一个新的、特别的地方供莉莉玩耍。'] ['<pad> <extra_id_0>, Fluffy, Fluffy</s><pad><pad><pad>', '<pad> <extra_id_0>, a palace, called.</s>'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# validloss += [output.loss.item()]\u001b[39;00m\n\u001b[1;32m     35\u001b[0m references \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/generation/utils.py:1544\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1527\u001b[0m         input_ids,\n\u001b[1;32m   1528\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1541\u001b[0m     )\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/generation/utils.py:2404\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2401\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2404\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2412\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:1776\u001b[0m, in \u001b[0;36mMT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1776\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:1101\u001b[0m, in \u001b[0;36mMT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1087\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1088\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         output_attentions,\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:602\u001b[0m, in \u001b[0;36mMT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     query_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "max_eval_codebleu = 0\n",
    "iter_to_accumlate = 4\n",
    "epochloss = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    allloss = 0\n",
    "    for step,batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch.to(device)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss/iter_to_accumlate\n",
    "        loss.backward()\n",
    "        allloss += loss.item()\n",
    "        epochloss.append(loss.item())\n",
    "        if (step+1)%iter_to_accumlate==0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        if (step+1)%(4*iter_to_accumlate) == 0:\n",
    "            print(\"epoch\",epoch,\"step\",step,\"loss\",loss,sep=\" \")\n",
    "    print(\"epoch\",epoch,\"trainLoss:\",allloss/(len(train_dataloader)*4))\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    validloss = []\n",
    "    all_me = []\n",
    "    for step,batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**batch)\n",
    "        # validloss += [output.loss.item()]\n",
    "        references = []\n",
    "        hypothesis = []\n",
    "        label_strs = tokenizer.batch_decode(batch['labels'].cpu(),skip_special_tokens = True)\n",
    "        output_strs = tokenizer.batch_decode(output.cpu())\n",
    "        for i in range(len(label_strs)):\n",
    "            all_me.append(bleu.sentence_bleu(references= [label_strs[i].split()], hypothesis=output_strs[i].split()))\n",
    "        print(label_strs,output_strs,all_me)\n",
    "    eval_bleu = sum(all_me)/len(all_me)\n",
    "    print(\"epoch \",epoch,\"bleu \",eval_bleu)\n",
    "    if eval_bleu > max_eval_codebleu:\n",
    "        min_eval_codebleu = eval_bleu\n",
    "        model.save_pretrained(\"Jchew/mT5ForTranslate_English2Chinese\")\n",
    "        model.push_to_hub(\"Jchew/mT5ForTranslate_English2Chinese\")\n",
    "        tokenizer.push_to_hub(\"Jchew/mT5ForTranslate_English2Chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
